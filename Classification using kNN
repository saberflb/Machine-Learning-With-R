Data Set: http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29

################################### load data and play around
data<- read.csv("wdbc.data.txt", stringsAsFactors = FALSE)

# Get an idea of the structure of the data
str(data)
dim(data)
rownames(data)
colnames(data)


# From the result it looks like the data is missing colnames. We add the names
colnames(data)<-c("id","diagnosis", "radius_mean","texture_mean", "perimeter_mean", "area_mean")

#################################### "id" is not an interested attribute
data<-data[-1]

#################################### "diagnosis" is an important attribute of type char. We will make it factor for classification.
table(data$diagnosis)

# Since Machine Learning (ML) classifiers require target feature as "factor"
summary(data$diagnosis) 
data$diagnosis<- factor(data$diagnosis, levels=c("B","M"), labels=c("Benign","Malignant"))

round(prop.table(table(data$diagnosis))*100, digits=1)

#################################### The remaining 30 features are all "numeric". We focus on the first 3 features.

######### Normalize Data
summary(data[c("radius_mean","area_mean", "perimeter_mean")])

# Recall the distance calculation for k-NN heavily depends on the measurement scale of the input features. This requires normalization to rescale the features above to a standard range of values.

normalize<-function(x){
	return ((x-min(x))/(max(x)-min(x)))
}

# lapply() function takes a list and applies a specified function to each list element. A data frame is a list of equal length vectors.

ndata<- as.data.frame(lapply(data[2:31], normalize))
summary(ndata[c("radius_mean","area_mean", "perimeter_mean")])

########## Data Preparation (Create Training and Test Datasets)

train<- ndata[1:469, ]
test<- ndata[470:568,]

# "diagnosis" is our target variable 
train_label<-data[1:469,1]
test_label<-data[470:568,1]

########### Training a Model on the data

#install.packages("class")

predict<-knn(train= train, test= test, cl=train_label, k=21)

########### Evaluating Model Performance

#install.packages("gmodels")
#library(gmodels)
CrossTable(x=test_label, y=predict, prop.chisq=FALSE)

########### Improving Model Performance 
# Different Normalization Scheme
# kNN with different k
















